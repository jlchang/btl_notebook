{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "info in /btl/data/cleanup/README\n",
    "ARCHIVE:\n",
    "To archive a directory (must be a subdirectory of /btl/projects or /btl/data) simply add the absolute path to the file\n",
    "archiveList (one directory per line, WITHOUT ending \"/\"s) and then (on a node with SGE access such as stout)\n",
    "execute archiveSubmit.\n",
    "\n",
    "The archived files are placed in /btl/archive/data or /btl/archive/projects with a subdirectory of whatever comes after\n",
    "/btl/projects or /btl/data in the input spec.  For example, if there's a directory /btl/projects/SSF/P1/myDir being\n",
    "archived it will wind up in /btl/archive/projects/SSF/P1/myDir.tar.gz\n",
    "\n",
    "\n",
    "CLEANUP:\n",
    "To cleanup additional directories add a line to the cleanupCrontab file and then, on stout, reset the crontab job for\n",
    "nnovod to be what cleanupCrontab contains.\n",
    "\n",
    "Each job is submitted via the cleanupSubmit script with 2 mandatory parameters and 1 optional one:\n",
    "action directory optional_number_of_days\n",
    "where\n",
    "action is either zipup or laneCleanup - zipup to zipup fasta files, laneCleanup to cleanup sequencer binary files and\n",
    "then archive the run directory\n",
    "\n",
    "directory is where to look for files (unlimited depth searched) - this is usually a MiSeq run directory\n",
    "\n",
    "optional_number_of_days is an optional parameters specifying the minimum number of days old the files must be before\n",
    "they are zipped or deleted, by default this is 60 for laneCleanup and 70 for zipup\n",
    "\n",
    "See cleanupCrontab for examples of cleanupSubmit usage.\n",
    "\n",
    "\n",
    "Logging of results:\n",
    "All actions are logged in the logs subdirectory with names that include the date when the job was submitted."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If more than one set of archiving needs to be done, create archiveList1 and run archiveSubmit1 (archiveSubmit2 also exists)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "other items to investigate:\n",
    "/btl/data/cleanup/doNotArchiveList\n",
    "/btl/data/cleanup/playSubmit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Archiving issues when walkup dir locked or only partially unlocked\n",
    "\n",
    "Expected walkup data folder structure\n",
    "/btl/data/walkup/<expt type>/SSF-XXXX/data/<flowcell>/<rundir>/<lanes and manifest>...\n",
    "\n",
    "expected permissions drwxrwsr-x (btl group-owned) from SSF-XXXX level on down\n",
    "\n",
    "A. data not unlocked\n",
    "-> data is archived but original data cannot be deleted\n",
    "B. highest unlocked level not SSF-XXXX (ie. at flowcell or below)\n",
    "-> data is archived, original data with expected permissions are deleted but higher directories remain\n",
    "IF an archive RETRY is attempted, the empty folders form a small tarball that OVERWRITES the original archived data.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "improvements \n",
    "\n",
    "check for locked directories\n",
    "namei -l /btl/data/walkup/*/SSF-1972/data/*/*/info/ | grep -v root | grep rwxr-s\n",
    "\n",
    "check if tarball already exists\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Checking for locked directories\n",
    "\n",
    "for i in `cut -d \"/\" -f 6 data_cleanup_orig`; do echo $i; namei -l /btl/data/walkup/*/$i/data/*/*/info/ | grep -v root | grep rwxr-s ; done\n",
    "SSF-2004\n",
    "namei: failed to stat: /btl/data/walkup/*/SSF-2004/data/*/*/info/: No such file or directory\n",
    "SSF-2059\n",
    "drwxr-sr-x jboch  btl  HYYV7BGXY\n",
    "drwxr-sr-x jboch  btl  C1-83_2016-12-08_2016-12-08\n",
    "drwxr-sr-x jboch  btl  info\n",
    "SSF-2091\n",
    "SSF-2095\n",
    "SSF-2104\n",
    "SSF-2106\n",
    "SSF-2107\n",
    "SSF-2108\n",
    "SSF-2109\n",
    "SSF-2110\n",
    "SSF-2117\n",
    "SSF-2119\n",
    "SSF-2123\n",
    "SSF-2147\n",
    "SSF-2157\n",
    "SSF-2160\n",
    "SSF-1972\n",
    "namei: failed to stat: /btl/data/walkup/*/SSF-1972/data/*/*/info/: No such file or directory\n",
    "SSF-2093\n",
    "SSF-2094\n",
    "SSF-2097"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Determining size of archive list\n",
    "\n",
    "make file of directories to be archived \"data_cleanup\"\n",
    "for i in `cat data_cleanup`; do du -hs $i; done > size_cleanup\n",
    "VISUAL/Manual: Check size cleanup to see if all are Gigabyte sized files\n",
    "\n",
    "grep [0-9]G size_cleanup | cut -d \"G\" -f 1 | awk '{ sum += $1 } END { print sum }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5649.3\n"
     ]
    }
   ],
   "source": [
    "cd /broad/hptmp/jlchang\n",
    "grep [0-9]G proj_size_cleanup | cut -d \"G\" -f 1 | awk '{ sum += $1 } END { print sum }'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "remove DGE analysis >100G - Scott will delete intermediate files before we archive (proj_size_cleanup_heldForCleanup.archiveList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2973.3\n"
     ]
    }
   ],
   "source": [
    "grep [0-9]G proj_size_cleanup_smallOnly | cut -d \"G\" -f 1 | awk '{ sum += $1 } END { print sum }'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
